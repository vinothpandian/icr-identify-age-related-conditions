{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from metrics.loss import balanced_log_loss\n",
    "import pandas as pd\n",
    "from fastai.tabular.core import cont_cat_split\n",
    "from sklearn import model_selection, metrics, inspection\n",
    "from visualize.results import plot_results\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "path = Path(\"./data\")\n",
    "output_path = Path(\"./submission\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(X, y):\n",
    "    sampler = SMOTE()\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((370, 57), (247, 57))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(path / \"train.csv\", index_col=\"Id\")\n",
    "\n",
    "drop_cols = [\"EJ\"]\n",
    "dep_vars = [\"Class\"]\n",
    "\n",
    "untrainable_cols = drop_cols + dep_vars\n",
    "\n",
    "# Drops the dep_vars before splitting categorical and continuous variables\n",
    "cont_names, cat_names = cont_cat_split(train_df, dep_var=untrainable_cols)\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(train_df, test_size=0.4, random_state=33)\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = get_preprocess_pipeline(train_df, cont_names, cat_names, untrainable_cols)\n",
    "X_pre = preprocessor.fit_transform(train_df.drop(columns=untrainable_cols))\n",
    "train_df = pd.merge(X_pre, train_df[untrainable_cols], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocessor.transform(test_df.drop(columns=untrainable_cols, errors=\"ignore\"))\n",
    "y_test = test_df[dep_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=untrainable_cols, errors=\"ignore\")\n",
    "y = train_df[dep_vars]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembe - Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "xgm_clf = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    colsample_bylevel=0.3,\n",
    "    colsample_bynode=0.7,\n",
    "    colsample_bytree=1.0,\n",
    "    gamma=0.6,\n",
    "    learning_rate=0.0344,\n",
    "    max_depth=3,\n",
    "    min_child_weight=0.5,\n",
    "    n_estimators=650,\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    scale_pos_weight=5.5,\n",
    "    subsample=0.6,\n",
    "    tree_method=\"hist\",\n",
    "    eval_metric=balanced_log_loss,\n",
    ")\n",
    "\n",
    "lgbm_clf = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    verbosity=-1,\n",
    "    boosting_type=\"gbdt\",\n",
    "    learning_rate=0.046,\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    scale_pos_weight=10.0,\n",
    "    subsample=0.9,\n",
    "    reg_alpha=3.5,\n",
    "    reg_lambda=2.5,\n",
    "    colsample_bytree=1.0,\n",
    "    colsample_bynode=0.6,\n",
    "    data_sample_strategy=\"bagging\",\n",
    "    num_leaves=6329,\n",
    "    max_bin=401,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# cat_clf = CatBoostClassifier(\n",
    "#     bagging_temperature=0.5,\n",
    "#     border_count=29,\n",
    "#     depth=3,\n",
    "#     grow_policy=\"SymmetricTree\",\n",
    "#     iterations=550,\n",
    "#     l2_leaf_reg=6.0,\n",
    "#     verbose=0,\n",
    "#     task_type=\"GPU\",\n",
    "#     devices=\"0\",\n",
    "# )\n",
    "\n",
    "tabpfn_clf = TabPFNClassifier(device='cuda', N_ensemble_configurations=64, only_inference=False, no_preprocess_mode=True)\n",
    "    \n",
    "\n",
    "ensemble_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"xgm\", xgm_clf),\n",
    "        (\"lgbm\", lgbm_clf),\n",
    "        (\"tabpfn\", tabpfn_clf),\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=4)\n",
    "\n",
    "for idx in kfold.split(X, y):\n",
    "    train_idx, _ = idx\n",
    "    X_train = X.iloc[train_idx]\n",
    "    y_train = y.iloc[train_idx]\n",
    "\n",
    "    X_res, y_res = resample(X_train, y_train.values.ravel())\n",
    "\n",
    "    ensemble_clf.fit(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.0472\n",
      "Balanced log loss: 0.0635\n",
      "Accuracy: 0.9919\n",
      "Kappa: 0.9682\n",
      "F1: 0.9730\n"
     ]
    }
   ],
   "source": [
    "pred_probs = ensemble_clf.predict_proba(X)\n",
    "y_true = y.values.ravel()\n",
    "\n",
    "y_pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "log_loss_val = metrics.log_loss(y_true, pred_probs)\n",
    "balanced_log_loss_val = balanced_log_loss(y_true, pred_probs)\n",
    "\n",
    "accuracy_val = metrics.accuracy_score(y_true, y_pred)\n",
    "kappa_val = metrics.cohen_kappa_score(y_true, y_pred)\n",
    "f1_val = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Log loss: {log_loss_val:.4f}\")\n",
    "print(f\"Balanced log loss: {balanced_log_loss_val:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Kappa: {kappa_val:.4f}\")\n",
    "print(f\"F1: {f1_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/lightgbm/basic.py:701: DeprecationWarning:\n",
      "\n",
      "np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
      "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss: 0.2009\n",
      "Balanced log loss: 0.2639\n",
      "Accuracy: 0.9231\n",
      "Kappa: 0.7702\n",
      "F1: 0.8190\n"
     ]
    }
   ],
   "source": [
    "pred_probs = ensemble_clf.predict_proba(X_test)\n",
    "y_true = y_test.values.ravel()\n",
    "\n",
    "y_pred = pred_probs.argmax(axis=1)\n",
    "\n",
    "log_loss_val = metrics.log_loss(y_true, pred_probs)\n",
    "balanced_log_loss_val = balanced_log_loss(y_true, pred_probs)\n",
    "\n",
    "accuracy_val = metrics.accuracy_score(y_true, y_pred)\n",
    "kappa_val = metrics.cohen_kappa_score(y_true, y_pred)\n",
    "f1_val = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Log loss: {log_loss_val:.4f}\")\n",
    "print(f\"Balanced log loss: {balanced_log_loss_val:.4f}\")\n",
    "print(f\"Accuracy: {accuracy_val:.4f}\")\n",
    "print(f\"Kappa: {kappa_val:.4f}\")\n",
    "print(f\"F1: {f1_val:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from fastai.tabular.core import cont_cat_split\n",
    "import pandas as pd\n",
    "from sklearn import compose, impute, pipeline, preprocessing, model_selection\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from fastai.tabular.all import Tensor, torch, store_attr\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.192862Z",
     "start_time": "2023-08-07T21:51:56.624576Z"
    }
   },
   "id": "ab7d923da0a3f996"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d592bdc3a8ded145"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    nc = np.bincount(y_true)\n",
    "    return metrics.log_loss(y_true, y_pred, sample_weight=1 / nc[y_true], eps=1e-15)\n",
    "\n",
    "\n",
    "def balanced_log_loss_tensor(output: Tensor, target: Tensor):\n",
    "    y_true = target.flatten().cpu().detach().numpy()\n",
    "    y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "    try:\n",
    "        loss_value = balanced_log_loss(y_true, y_pred)\n",
    "    except Exception:\n",
    "        return torch.tensor(0.0, dtype=torch.float32, device=output.device, requires_grad=True)\n",
    "    return torch.tensor(loss_value, dtype=torch.float32, device=output.device, requires_grad=True)\n",
    "\n",
    "\n",
    "class BalancedLogLossMetric:\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error / weight\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        y_true = np.array(target).astype(int)\n",
    "        y_pred = np.array(approxes[0])\n",
    "        nc = np.bincount(y_true)\n",
    "        balanced_logloss = metrics.log_loss(y_true, y_pred, sample_weight=1 / nc[y_true], eps=1e-15)\n",
    "        return balanced_logloss, 1.0\n",
    "\n",
    "\n",
    "class BalancedLogLoss:\n",
    "    y_int = True\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        store_attr()\n",
    "\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        return balanced_log_loss_tensor(inp, targ)\n",
    "\n",
    "    def activation(self, out: Tensor) -> Tensor:\n",
    "        return F.softmax(out, dim=-1)\n",
    "\n",
    "    def decodes(self, out: Tensor) -> Tensor:\n",
    "        return out.argmax(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.210332Z",
     "start_time": "2023-08-07T21:51:59.198003Z"
    }
   },
   "id": "b77ae161aa830418"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b952a282729ea46"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import compose, ensemble, impute, pipeline, preprocessing, tree\n",
    "\n",
    "\n",
    "def get_preprocess_pipeline(df, cont_cols, cat_cols, drop_cols):\n",
    "    \"\"\"\n",
    "    Returns a pipeline that performs the following transformations:\n",
    "    * Standard scaling\n",
    "    * Log transformation\n",
    "    * Reciprocal transformation\n",
    "    * Box-Cox transformation\n",
    "    * Yeo-Johnson transformation\n",
    "    * Categorical imputing\n",
    "    * Semi-constant feature binarization\n",
    "\n",
    "    Based on the EDA from https://www.kaggle.com/code/mateuszk013/icr-eda-balanced-learning-with-lgbm-xgb/notebook\n",
    "\n",
    "    :param df: The dataframe to be transformed.\n",
    "    :type df: pandas.DataFrame\n",
    "    :param cont_names: The names of the continuous variables.\n",
    "    :type cont_names: list of str\n",
    "    :param dep_vars: The names of the dependent variables.\n",
    "    :type dep_vars: list of str\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify columns that doesn't follow a normal distribution\n",
    "    # find an appropriate transformation for them to follow a normal distribution\n",
    "    r2_scores = defaultdict(tuple)\n",
    "\n",
    "    for feature in cont_cols:\n",
    "        orig = df[feature].dropna()\n",
    "        _, (*_, R_orig) = stats.probplot(orig, rvalue=True)\n",
    "        _, (*_, R_log) = stats.probplot(np.log(orig), rvalue=True)\n",
    "        _, (*_, R_sqrt) = stats.probplot(np.sqrt(orig), rvalue=True)\n",
    "        _, (*_, R_reci) = stats.probplot(np.reciprocal(orig), rvalue=True)\n",
    "        _, (*_, R_boxcox) = stats.probplot(stats.boxcox(orig)[0], rvalue=True)\n",
    "        _, (*_, R_yeojohn) = stats.probplot(stats.yeojohnson(orig)[0], rvalue=True)\n",
    "        r2_scores[feature] = (\n",
    "            R_orig * R_orig,\n",
    "            R_log * R_log,\n",
    "            R_sqrt * R_sqrt,\n",
    "            R_reci * R_reci,\n",
    "            R_boxcox * R_boxcox,\n",
    "            R_yeojohn * R_yeojohn,\n",
    "        )\n",
    "\n",
    "    r2_scores = pd.DataFrame(\n",
    "        r2_scores,\n",
    "        index=(\"Original\", \"Log\", \"Sqrt\", \"Reciprocal\", \"BoxCox\", \"YeoJohnson\"),\n",
    "    ).T\n",
    "\n",
    "    r2_scores[\"Winner\"] = r2_scores.idxmax(axis=1)\n",
    "\n",
    "    # Identify columns to be transformed\n",
    "    no_transform_cols = r2_scores.query(\"Winner == 'Original'\").index\n",
    "    log_transform_cols = r2_scores.query(\"Winner == 'Log'\").index\n",
    "    reciprocal_transform_cols = r2_scores.query(\"Winner == 'Reciprocal'\").index\n",
    "    boxcox_transform_cols = r2_scores.query(\"Winner == 'BoxCox'\").index\n",
    "    yeojohnson_transform_cols = r2_scores.query(\"Winner == 'YeoJohnson'\").index\n",
    "\n",
    "    # Identify columns that are constant or semi-constant\n",
    "    numeric_descr = df.drop(columns=drop_cols).describe().T\n",
    "    semi_constant_mask = np.isclose(numeric_descr[\"min\"], numeric_descr[\"50%\"])\n",
    "    semi_constant_descr = numeric_descr[semi_constant_mask]\n",
    "    semi_const_cols_thresholds = semi_constant_descr[\"50%\"].to_dict()\n",
    "\n",
    "    # List of columns to be transformed\n",
    "    semi_const_cols = semi_const_cols_thresholds.keys()\n",
    "    no_transform_cols = no_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    log_transform_cols = log_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    reciprocal_transform_cols = reciprocal_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    boxcox_transform_cols = boxcox_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    yeojohnson_transform_cols = yeojohnson_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "\n",
    "    # Transformations\n",
    "    standard_scaling = (\n",
    "        preprocessing.StandardScaler(),\n",
    "        no_transform_cols,\n",
    "    )\n",
    "    log_transform = (\n",
    "        pipeline.make_pipeline(\n",
    "            preprocessing.FunctionTransformer(func=np.log, feature_names_out=\"one-to-one\"),\n",
    "            preprocessing.StandardScaler(),\n",
    "        ),\n",
    "        log_transform_cols,\n",
    "    )\n",
    "    reciprocal_transform = (\n",
    "        pipeline.make_pipeline(\n",
    "            preprocessing.FunctionTransformer(func=np.reciprocal, feature_names_out=\"one-to-one\"),\n",
    "            preprocessing.StandardScaler(),\n",
    "        ),\n",
    "        reciprocal_transform_cols,\n",
    "    )\n",
    "    boxcox_transform = (\n",
    "        preprocessing.PowerTransformer(method=\"box-cox\", standardize=True),\n",
    "        boxcox_transform_cols,\n",
    "    )\n",
    "    yeojohnson_transform = (\n",
    "        preprocessing.PowerTransformer(method=\"yeo-johnson\", standardize=True),\n",
    "        yeojohnson_transform_cols,\n",
    "    )\n",
    "\n",
    "    # Other transformations\n",
    "    categorical_imputing = (\n",
    "        pipeline.make_pipeline(\n",
    "            impute.SimpleImputer(strategy=\"most_frequent\"),\n",
    "            preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "        ),\n",
    "        cat_cols,  # type: ignore\n",
    "    )\n",
    "    semi_const_transforms = [\n",
    "        (\n",
    "            pipeline.make_pipeline(\n",
    "                impute.SimpleImputer(strategy=\"median\"),\n",
    "                preprocessing.Binarizer(threshold=thresh),\n",
    "            ),\n",
    "            [col],\n",
    "        )\n",
    "        for col, thresh in semi_const_cols_thresholds.items()\n",
    "    ]\n",
    "\n",
    "    return pipeline.make_pipeline(\n",
    "        compose.make_column_transformer(\n",
    "            standard_scaling,\n",
    "            log_transform,\n",
    "            reciprocal_transform,\n",
    "            boxcox_transform,\n",
    "            yeojohnson_transform,\n",
    "            categorical_imputing,\n",
    "            *semi_const_transforms,\n",
    "            remainder=\"drop\",\n",
    "            verbose_feature_names_out=False,\n",
    "        ),\n",
    "        impute.KNNImputer(n_neighbors=10, weights=\"distance\"),\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "def get_tree_preprocess_pipeline():\n",
    "    return pipeline.make_pipeline(\n",
    "        impute.KNNImputer(n_neighbors=10, weights=\"distance\"),\n",
    "    ).set_output(transform=\"pandas\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.238692Z",
     "start_time": "2023-08-07T21:51:59.210460Z"
    }
   },
   "id": "31d08d53d8f3bcd9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path(\"./data\")\n",
    "output = Path(\"./output\")\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(path / \"train.csv\", index_col=\"Id\")\n",
    "dep_vars = [\"Class\"]\n",
    "\n",
    "drop_vars = [\"EJ\"]\n",
    "df.drop(columns=drop_vars, inplace=True)\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(df, test_size=0.4, stratify=df[dep_vars], random_state=33)\n",
    "\n",
    "\n",
    "def get_preprocessed_data(train_df, test_df, dep_vars):\n",
    "    cont_names, cat_names = cont_cat_split(df, dep_var=dep_vars)\n",
    "\n",
    "    preprocessor = get_preprocess_pipeline(df, cont_names, cat_names, dep_vars)\n",
    "\n",
    "    # Preprocess training data\n",
    "    X_pre = preprocessor.fit_transform(train_df.drop(columns=dep_vars))\n",
    "    train_df = pd.merge(X_pre, train_df[dep_vars], left_index=True, right_index=True)\n",
    "    X = train_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y = train_df[dep_vars]\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_pre = preprocessor.transform(test_df.drop(columns=dep_vars))\n",
    "    test_df = pd.merge(X_test_pre, test_df[dep_vars], left_index=True, right_index=True)\n",
    "    X_test = test_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y_test = test_df[dep_vars]\n",
    "\n",
    "    return X, y, X_test, y_test\n",
    "\n",
    "\n",
    "def get_tree_preprocessed_data(train_df, test_df, dep_vars):\n",
    "    preprocessor = get_tree_preprocess_pipeline()\n",
    "\n",
    "    # Preprocess training data\n",
    "    X_pre = preprocessor.fit_transform(train_df.drop(columns=dep_vars))\n",
    "    train_df = pd.merge(X_pre, train_df[dep_vars], left_index=True, right_index=True)\n",
    "    X = train_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y = train_df[dep_vars]\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_pre = preprocessor.transform(test_df.drop(columns=dep_vars))\n",
    "    test_df = pd.merge(X_test_pre, test_df[dep_vars], left_index=True, right_index=True)\n",
    "    X_test = test_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y_test = test_df[dep_vars]\n",
    "\n",
    "    # Calculate scale_pos_weight\n",
    "    scale_pos_weight = df[\"Class\"].value_counts()[0] / df[\"Class\"].value_counts()[1]\n",
    "\n",
    "    return X, y, X_test, y_test, scale_pos_weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.256760Z",
     "start_time": "2023-08-07T21:51:59.239547Z"
    }
   },
   "id": "865eae9e43791a21"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "def resample(X, y):\n",
    "    sampler = SMOTE()\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.288956Z",
     "start_time": "2023-08-07T21:51:59.259327Z"
    }
   },
   "id": "2e84cd9ab326f67a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model param getters from Optuna"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cae6eddf512b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.332541Z",
     "start_time": "2023-08-07T21:51:59.332416Z"
    }
   },
   "outputs": [],
   "source": [
    "best_trials = {\n",
    "    \"lightgbm_with_resampling\": 248,\n",
    "    \"lightgbm_without_resampling\": 220,\n",
    "    \"svc_without_resampling\": 203,\n",
    "    \"svc_with_resampling\": 161,\n",
    "    \"catboost_with_resampling\": 234,\n",
    "    \"catboost_without_resampling\": 223,\n",
    "    \"fastai_with_resampling\": 123,\n",
    "    \"fastai_without_resampling\": 101,\n",
    "    \"tabpfn_without_resampling\": 30,\n",
    "    \"tabpfn_with_resampling\": 65,\n",
    "    \"xgboost_without_resampling\": 210,\n",
    "    \"xgboost_with_resampling\": 179,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "optuna_storage = \"sqlite:///icr-ensemble-experiments.db\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:51:59.332613Z",
     "start_time": "2023-08-07T21:51:59.332520Z"
    }
   },
   "id": "e06554d32a11fa3f"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "estimator_params = {}\n",
    "for study_name, trial_id in best_trials.items():\n",
    "    study = optuna.load_study(study_name=study_name, storage=optuna_storage)\n",
    "    best_trial = best_trials[study_name]\n",
    "    estimator_params[study_name] = study.trials[trial_id].params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:01.473021Z",
     "start_time": "2023-08-07T21:51:59.332570Z"
    }
   },
   "id": "5eed160c1ee1e821"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 0.10494454342481872,\n 'degree': 8,\n 'gamma': 3.4748581836487165,\n 'kernel': 'linear'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_params[\"svc_with_resampling\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:01.517632Z",
     "start_time": "2023-08-07T21:52:01.467914Z"
    }
   },
   "id": "8ab3342c8064deb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def get_xgboost_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = (\n",
    "            dict(\n",
    "                booster=\"gbtree\",\n",
    "                tree_method=\"gpu_hist\",\n",
    "                gpu_id=0,\n",
    "                predictor=\"gpu_predictor\",\n",
    "                enable_categorical=True,\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "            )\n",
    "            | optuna_params\n",
    "    )\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        eval_metric=balanced_log_loss,\n",
    "    )\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    targs = y_test.values.ravel()\n",
    "    ypreds = model.predict_proba(X_test)\n",
    "    test_loss = balanced_log_loss(targs, ypreds)\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:01.517726Z",
     "start_time": "2023-08-07T21:52:01.516210Z"
    }
   },
   "id": "58b6004001f46e2a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2845993352213135\n",
      "Test loss: 0.3305988644206436\n",
      "Validation loss: 0.36223432237973197\n",
      "Test loss: 0.33772422521736284\n"
     ]
    }
   ],
   "source": [
    "xgboost_with_resampling = get_xgboost_estimator(\"xgboost_with_resampling\")\n",
    "xgboost_without_resampling = get_xgboost_estimator(\"xgboost_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:17.023770Z",
     "start_time": "2023-08-07T21:52:01.516339Z"
    }
   },
   "id": "7c4f8fcb9a435e64"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def get_lightgbm_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = (\n",
    "            dict(\n",
    "                boosting_type=\"gbdt\",\n",
    "                device=\"gpu\",\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "                data_sample_strategy=\"bagging\",\n",
    "                n_jobs=-1,\n",
    "            )\n",
    "            | optuna_params\n",
    "    )\n",
    "\n",
    "    model = LGBMClassifier(**params, objective=\"binary\", verbosity=-1)\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit, eval_metric=balanced_log_loss)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    targs = y_test.values.ravel()\n",
    "    ypreds = model.predict_proba(X_test)\n",
    "    test_loss = balanced_log_loss(targs, ypreds)\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:17.072030Z",
     "start_time": "2023-08-07T21:52:17.029364Z"
    }
   },
   "id": "abb393dd37adc5f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2757865588037478\n",
      "Test loss: 0.28649360810902763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m lightgbm_with_resampling \u001B[38;5;241m=\u001B[39m get_lightgbm_estimator(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlightgbm_with_resampling\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lightgbm_without_resampling \u001B[38;5;241m=\u001B[39m \u001B[43mget_lightgbm_estimator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlightgbm_without_resampling\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[12], line 38\u001B[0m, in \u001B[0;36mget_lightgbm_estimator\u001B[0;34m(name)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_resample:\n\u001B[1;32m     36\u001B[0m     X_fit, y_fit \u001B[38;5;241m=\u001B[39m resample(X_train, y_train)\n\u001B[0;32m---> 38\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_fit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_fit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbalanced_log_loss\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m val_preds \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(X_val)\n\u001B[1;32m     41\u001B[0m val_loss \u001B[38;5;241m=\u001B[39m balanced_log_loss(y_val, val_preds)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/envs/kaggle/lib/python3.11/site-packages/lightgbm/sklearn.py:1142\u001B[0m, in \u001B[0;36mLGBMClassifier.fit\u001B[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m   1139\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1140\u001B[0m             valid_sets\u001B[38;5;241m.\u001B[39mappend((valid_x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_le\u001B[38;5;241m.\u001B[39mtransform(valid_y)))\n\u001B[0;32m-> 1142\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_sample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_class_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_class_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_init_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_init_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcategorical_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategorical_feature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/envs/kaggle/lib/python3.11/site-packages/lightgbm/sklearn.py:842\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m    839\u001B[0m evals_result: _EvalResultDict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    840\u001B[0m callbacks\u001B[38;5;241m.\u001B[39mappend(record_evaluation(evals_result))\n\u001B[0;32m--> 842\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    843\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    844\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    845\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_boost_round\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_estimators\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_sets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    847\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalid_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    848\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metrics_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    849\u001B[0m \u001B[43m    \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    850\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    851\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_evals_result \u001B[38;5;241m=\u001B[39m evals_result\n\u001B[1;32m    855\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_best_iteration \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster\u001B[38;5;241m.\u001B[39mbest_iteration\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/envs/kaggle/lib/python3.11/site-packages/lightgbm/engine.py:266\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001B[0m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cb \u001B[38;5;129;01min\u001B[39;00m callbacks_before_iter:\n\u001B[1;32m    259\u001B[0m     cb(callback\u001B[38;5;241m.\u001B[39mCallbackEnv(model\u001B[38;5;241m=\u001B[39mbooster,\n\u001B[1;32m    260\u001B[0m                             params\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m    261\u001B[0m                             iteration\u001B[38;5;241m=\u001B[39mi,\n\u001B[1;32m    262\u001B[0m                             begin_iteration\u001B[38;5;241m=\u001B[39minit_iteration,\n\u001B[1;32m    263\u001B[0m                             end_iteration\u001B[38;5;241m=\u001B[39minit_iteration \u001B[38;5;241m+\u001B[39m num_boost_round,\n\u001B[1;32m    264\u001B[0m                             evaluation_result_list\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m--> 266\u001B[0m \u001B[43mbooster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    268\u001B[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    269\u001B[0m \u001B[38;5;66;03m# check evaluation result.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.2/envs/kaggle/lib/python3.11/site-packages/lightgbm/basic.py:3557\u001B[0m, in \u001B[0;36mBooster.update\u001B[0;34m(self, train_set, fobj)\u001B[0m\n\u001B[1;32m   3555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__set_objective_to_none:\n\u001B[1;32m   3556\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LightGBMError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCannot update due to null objective function.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 3557\u001B[0m _safe_call(\u001B[43m_LIB\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLGBM_BoosterUpdateOneIter\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3558\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbyref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mis_finished\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   3560\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__is_predicted_cur_iter \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__num_dataset)]\n\u001B[1;32m   3561\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m is_finished\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lightgbm_with_resampling = get_lightgbm_estimator(\"lightgbm_with_resampling\")\n",
    "lightgbm_without_resampling = get_lightgbm_estimator(\"lightgbm_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:27.528690Z",
     "start_time": "2023-08-07T21:52:17.071981Z"
    }
   },
   "id": "dbe6618be76154f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def get_svc_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test = get_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = (\n",
    "            dict(\n",
    "                probability=True,\n",
    "            )\n",
    "            | optuna_params\n",
    "    )\n",
    "\n",
    "    model = svm.SVC(**params)\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    targs = y_test.values.ravel()\n",
    "    ypreds = model.predict_proba(X_test)\n",
    "    test_loss = balanced_log_loss(targs, ypreds)\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.528624Z"
    }
   },
   "id": "a4fc52092cc67f58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svc_with_resampling = get_svc_estimator(\"svc_with_resampling\")\n",
    "svc_without_resampling = get_svc_estimator(\"svc_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:27.530136Z",
     "start_time": "2023-08-07T21:52:27.530055Z"
    }
   },
   "id": "6e21e919afb9b5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def get_catboost_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = (\n",
    "            dict(\n",
    "                grow_policy=\"SymmetricTree\",\n",
    "                verbose=0,\n",
    "                scale_pos_weight=scale_pos_weight,\n",
    "            )\n",
    "            | optuna_params\n",
    "    )\n",
    "\n",
    "    model = CatBoostClassifier(**params, eval_metric=BalancedLogLossMetric())\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    targs = y_test.values.ravel()\n",
    "    ypreds = model.predict_proba(X_test)\n",
    "    test_loss = balanced_log_loss(targs, ypreds)\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:27.530189Z",
     "start_time": "2023-08-07T21:52:27.530168Z"
    }
   },
   "id": "9944a596ce12e5ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "catboost_with_resampling = get_catboost_estimator(\"catboost_with_resampling\")\n",
    "catboost_without_resampling = get_catboost_estimator(\"catboost_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:27.531390Z",
     "start_time": "2023-08-07T21:52:27.530220Z"
    }
   },
   "id": "843542a6590cfbb4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "def get_tabpfn_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    params = estimator_params[name]\n",
    "    X, y, X_test, y_test, _ = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    model = TabPFNClassifier(\n",
    "        device=\"cuda\",\n",
    "        only_inference=False,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    X_fit, y_fit = X, y\n",
    "    if should_resample:\n",
    "        X_fit, y_fit = resample(X, y)\n",
    "\n",
    "    model.fit(X_fit, y_fit.values.ravel())\n",
    "\n",
    "    targs = y_test.values.ravel()\n",
    "    ypreds = model.predict_proba(X_test)\n",
    "    test_loss = balanced_log_loss(targs, ypreds)\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.530263Z"
    }
   },
   "id": "9d8f8c276920b3a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tabpfn_with_resampling = get_tabpfn_estimator(\"tabpfn_with_resampling\")\n",
    "tabpfn_without_resampling = get_tabpfn_estimator(\"tabpfn_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.530338Z"
    }
   },
   "id": "7ab7a4c100ba5481"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fastai.tabular.all import tabular_learner, tabular_config, TabularDataLoaders, CategoryBlock, FocalLossFlat, \\\n",
    "    TrainTestSplitter, EarlyStoppingCallback\n",
    "\n",
    "\n",
    "def get_fastai_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test = get_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    training_data = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "    if should_resample:\n",
    "        X_res, y_res = resample(X, y)\n",
    "        training_data = pd.merge(X_res, y_res, left_index=True, right_index=True)\n",
    "\n",
    "    testing_data = pd.merge(X_test, y_test, left_index=True, right_index=True)\n",
    "\n",
    "    layers_map = {\n",
    "        0: [2048, 1024, 512],\n",
    "        1: [2048, 1024, 512, 256],\n",
    "        2: [2048, 1024, 512, 256, 128],\n",
    "        3: [2048, 1024, 512, 256, 128],\n",
    "        4: [2048, 1024, 512, 256, 128, 64],\n",
    "        5: [2048, 1024, 512, 256, 128, 64, 32],\n",
    "        6: [2048, 1024, 512, 256, 128, 64, 32, 16],\n",
    "        7: [512, 256, 128, 64, 32, 16],\n",
    "        8: [256, 128, 64, 32, 16],\n",
    "        9: [128, 64, 32, 16],\n",
    "        10: [64, 32, 32, 16, 8],\n",
    "    }\n",
    "\n",
    "    bs = optuna_params.get(\"bs\")\n",
    "    epochs = optuna_params.get(\"epochs\")\n",
    "    layers_choice = optuna_params.get(\"layers_choice\")\n",
    "    layers = layers_map[layers_choice]\n",
    "\n",
    "    config = tabular_config(\n",
    "        ps=optuna_params.get(\"ps\"),\n",
    "        use_bn=optuna_params.get(\"use_bn\"),\n",
    "        bn_final=optuna_params.get(\"bn_final\"),\n",
    "        bn_cont=optuna_params.get(\"bn_cont\"),\n",
    "        lin_first=optuna_params.get(\"lin_first\"),\n",
    "    )\n",
    "\n",
    "    dls = TabularDataLoaders.from_df(\n",
    "        training_data,\n",
    "        y_names=dep_vars,\n",
    "        y_block=CategoryBlock,\n",
    "        bs=bs,\n",
    "        splits=TrainTestSplitter(\n",
    "            test_size=0.2,\n",
    "            stratify=train_df[dep_vars],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model = tabular_learner(\n",
    "        dls,\n",
    "        loss_func=FocalLossFlat(gamma=optuna_params.get(\"gamma\")),\n",
    "        layers=layers,\n",
    "        config=config,\n",
    "        cbs=[\n",
    "            EarlyStoppingCallback(min_delta=0.1, patience=8),\n",
    "        ],\n",
    "        wd=optuna_params.get(\"wd\"),\n",
    "        wd_bn_bias=optuna_params.get(\"wd_bn_bias\"),\n",
    "    )\n",
    "\n",
    "    with model.no_logging(), model.no_bar():\n",
    "        model.fit_one_cycle(epochs)\n",
    "\n",
    "    ypreds, targs = model.get_preds()\n",
    "    val_loss = balanced_log_loss_tensor(ypreds, targs).item()\n",
    "\n",
    "    test_dl = dls.test_dl(testing_data)\n",
    "    ypreds, targs = model.get_preds(dl=test_dl)\n",
    "    test_loss = balanced_log_loss_tensor(ypreds, targs).item()\n",
    "\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    print(f\"Test loss: {test_loss}\")\n",
    "\n",
    "    return ypreds, targs, model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.530380Z"
    }
   },
   "id": "a3fad9c4bca54f29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fastai_with_resampling = get_fastai_estimator(\"fastai_with_resampling\")\n",
    "fastai_without_resampling = get_fastai_estimator(\"fastai_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.530438Z"
    }
   },
   "id": "43f37562a0493f74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_normalized, y_normalized, X_test_normalized, y_test_normalized = get_preprocessed_data(train_df, test_df, dep_vars)\n",
    "X_tree, y_tree, X_test_tree, y_test_tree, _ = get_tree_preprocessed_data(train_df, test_df, dep_vars)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569468Z"
    }
   },
   "id": "30fc5978c10dd9bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    \"xgboost_with_resampling\": xgboost_with_resampling,\n",
    "    \"xgboost_without_resampling\": xgboost_without_resampling,\n",
    "    \"lightgbm_with_resampling\": lightgbm_with_resampling,\n",
    "    \"lightgbm_without_resampling\": lightgbm_without_resampling,\n",
    "    \"catboost_with_resampling\": catboost_with_resampling,\n",
    "    \"catboost_without_resampling\": catboost_without_resampling,\n",
    "    \"tabpfn_with_resampling\": tabpfn_with_resampling,\n",
    "    \"tabpfn_without_resampling\": tabpfn_without_resampling,\n",
    "    \"fastai_with_resampling\": fastai_with_resampling,\n",
    "    \"fastai_without_resampling\": fastai_without_resampling,\n",
    "    \"svc_with_resampling\": svc_with_resampling,\n",
    "    \"svc_without_resampling\": svc_without_resampling,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569539Z"
    }
   },
   "id": "a73dfa3f756a57f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = {name: ypreds[:, 1] for name, (ypreds, targs, model) in estimators.items()}\n",
    "\n",
    "scores = {}\n",
    "\n",
    "for name, (ypreds, targs, model) in estimators.items():\n",
    "    if name.startswith(\"fastai\"):\n",
    "        y_true = targs.cpu().detach().numpy().flatten()\n",
    "        y_pred = ypreds.cpu().detach().numpy()\n",
    "\n",
    "        scores[name] = [\n",
    "            balanced_log_loss(y_true, y_pred),\n",
    "            metrics.accuracy_score(y_true, np.argmax(y_pred, axis=1)),\n",
    "            metrics.precision_score(y_true, np.argmax(y_pred, axis=1)),\n",
    "            metrics.recall_score(y_true, np.argmax(y_pred, axis=1)),\n",
    "            metrics.f1_score(targs, np.argmax(ypreds, axis=1)),\n",
    "        ]\n",
    "    else:\n",
    "        scores[name] = [\n",
    "            balanced_log_loss(targs, ypreds),\n",
    "            metrics.accuracy_score(targs, np.argmax(ypreds, axis=1)),\n",
    "            metrics.precision_score(targs, np.argmax(ypreds, axis=1)),\n",
    "            metrics.recall_score(targs, np.argmax(ypreds, axis=1)),\n",
    "            metrics.f1_score(targs, np.argmax(ypreds, axis=1)),\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569579Z"
    }
   },
   "id": "459fc8bf907c9b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores, index=[\"balanced_log_loss\", \"accuracy\", \"precision\", \"recall\", \"f1\"]).T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569616Z"
    }
   },
   "id": "c527246c97dabad4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569658Z"
    }
   },
   "id": "141f8431e7dec0c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569690Z"
    }
   },
   "id": "980c0e354775e4a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_matrix = pred_df.corr(method=\"pearson\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569746Z"
    }
   },
   "id": "f64ab4b88bec738e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correlation_matrix[\"catboost_with_resampling\"].sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T21:52:27.601494Z",
     "start_time": "2023-08-07T21:52:27.569767Z"
    }
   },
   "id": "2268ec80f4b8b19e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.gapminder()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569787Z"
    }
   },
   "id": "f14eb787542e1a9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# melt pred_df and add targs as a column based on the index\n",
    "pred_df_melted = pred_df.reset_index().melt(id_vars=\"index\", var_name=\"model\", value_name=\"y_pred\")\n",
    "pred_df_melted[\"y_true\"] = pred_df_melted[\"index\"].apply(lambda x: targs[x])\n",
    "pred_df_melted"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569807Z"
    }
   },
   "id": "8b848df0c30838f0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    pred_df_melted,\n",
    "    x=\"y_pred\",\n",
    "    y=\"index\",\n",
    "    color=\"y_true\",\n",
    "    facet_col=\"model\",\n",
    "    facet_col_wrap=2,\n",
    "    color_discrete_sequence=[\"#010D36\", \"#FF2079\"],\n",
    "    category_orders={\"y_true\": (\"0\", \"1\")},\n",
    "    symbol=\"y_true\",\n",
    "    symbol_sequence=[\"diamond\", \"circle\"],\n",
    "    opacity=0.6,\n",
    "    height=1200,\n",
    "    width=840,\n",
    "    title=\"Training Dataset - Out of Fold Predictions\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569833Z"
    }
   },
   "id": "b79810f5d30eb466"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the correlation matrix heatmap using Plotly Express\n",
    "fig = px.imshow(correlation_matrix,\n",
    "                labels=dict(color=\"Correlation\"),\n",
    "                x=correlation_matrix.index,\n",
    "                y=correlation_matrix.columns,\n",
    "                color_continuous_scale='RdBu',\n",
    "                zmin=correlation_matrix.min().min(),\n",
    "                zmax=1)\n",
    "\n",
    "# Customize the heatmap layout\n",
    "fig.update_layout(\n",
    "    title=\"Correlation Matrix Heatmap\",\n",
    "    xaxis_title=\"Features\",\n",
    "    yaxis_title=\"Features\",\n",
    "    height=900,\n",
    "    width=840,\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569856Z"
    }
   },
   "id": "4585eecdcd912ca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Sample data (Replace this with your actual data)\n",
    "actual_labels = targs\n",
    "predicted_probs = pred_df['catboost_with_resampling']\n",
    "\n",
    "predicted_labels = np.where(predicted_probs > 0.5, 1, 0)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(actual_labels, predicted_labels)\n",
    "\n",
    "# Create a DataFrame to store the confusion matrix values\n",
    "df_conf_matrix = pd.DataFrame(conf_matrix, index=['Actual Negative', 'Actual Positive'],\n",
    "                              columns=['Predicted Negative', 'Predicted Positive'])\n",
    "\n",
    "df_conf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569877Z"
    }
   },
   "id": "2f251efaf4543b56"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ensemble"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4262b76b4cb84372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    w1 = trial.suggest_float(\"w1\", 0.1, 1.0, step=0.1)\n",
    "    w2 = trial.suggest_float(\"w2\", 0.1, 1.0, step=0.1)\n",
    "    w3 = trial.suggest_float(\"w3\", 0.1, 1.0, step=0.1)\n",
    "    w4 = trial.suggest_float(\"w4\", 0.1, 1.0, step=0.1)\n",
    "\n",
    "    total_weight = w1 + w2 + w3 + w4\n",
    "    w1 = w1 / total_weight\n",
    "    w2 = w2 / total_weight\n",
    "    w3 = w3 / total_weight\n",
    "    w4 = w4 / total_weight\n",
    "\n",
    "    predictions = [\n",
    "        pred_df[\"catboost_with_resampling\"].values,\n",
    "        pred_df[\"lightgbm_with_resampling\"].values,\n",
    "        pred_df[\"fastai_without_resampling\"].values,\n",
    "        pred_df[\"svc_without_resampling\"].values,\n",
    "    ]\n",
    "\n",
    "    ensemble_pred = (w1 * predictions[0] + w2 * predictions[1] + w3 * predictions[2] + w4 * predictions[\n",
    "        3]) / total_weight\n",
    "\n",
    "    return balanced_log_loss(targs, ensemble_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569897Z"
    }
   },
   "id": "ee362205d437cf47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optuna.delete_study(\n",
    "    study_name=\"ensemble_weights\",\n",
    "    storage=optuna_storage,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.569928Z"
    }
   },
   "id": "6985a4c0bc477be2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"ensemble_weights\",\n",
    "    storage=optuna_storage,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=250)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.570083Z"
    }
   },
   "id": "8bf0cc19d8f0e3f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for trial in study.best_trials:\n",
    "    print(trial.values)\n",
    "    print(trial.params)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.570152Z"
    }
   },
   "id": "7dc9d80f2c2f1136"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_weighted_preds(w1, w2, w3, w4):\n",
    "\n",
    "    total_weight = w1 + w2 + w3 + w4\n",
    "    w1 = w1 / total_weight\n",
    "    w2 = w2 / total_weight\n",
    "    w3 = w3 / total_weight\n",
    "    w4 = w4 / total_weight\n",
    "\n",
    "    predictions = [\n",
    "        pred_df[\"catboost_with_resampling\"].values,\n",
    "        pred_df[\"lightgbm_with_resampling\"].values,\n",
    "        pred_df[\"fastai_without_resampling\"].values,\n",
    "        pred_df[\"svc_without_resampling\"].values,\n",
    "    ]\n",
    "\n",
    "    ensemble_pred = (w1 * predictions[0] + w2 * predictions[1] + w3 * predictions[2] + w4 * predictions[\n",
    "        3]) / total_weight\n",
    "\n",
    "    return ensemble_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.570176Z"
    }
   },
   "id": "99594f6eb1966f10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from visualize.results import plot_results\n",
    "\n",
    "en_preds = get_weighted_preds(0.3, 0.4, 0.1, 0.1)\n",
    "print(balanced_log_loss(targs, en_preds))\n",
    "plot_results(targs, en_preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-07T21:52:27.570198Z"
    }
   },
   "id": "d41c44972742a83e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

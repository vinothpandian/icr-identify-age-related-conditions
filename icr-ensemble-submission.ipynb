{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import optuna\n",
    "from pathlib import Path\n",
    "import optuna\n",
    "from fastai.tabular.core import cont_cat_split\n",
    "import pandas as pd\n",
    "from sklearn import compose, impute, pipeline, preprocessing, model_selection\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from fastai.tabular.all import Tensor, torch, store_attr\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:19.566775Z",
     "start_time": "2023-08-07T04:04:19.529941Z"
    }
   },
   "id": "ab7d923da0a3f996"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d592bdc3a8ded145"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    nc = np.bincount(y_true)\n",
    "    return metrics.log_loss(y_true, y_pred, sample_weight=1 / nc[y_true], eps=1e-15)\n",
    "\n",
    "\n",
    "def balanced_log_loss_tensor(output: Tensor, target: Tensor):\n",
    "    y_true = target.flatten().cpu().detach().numpy()\n",
    "    y_pred = output.cpu().detach().numpy()\n",
    "\n",
    "    try:\n",
    "        loss_value = balanced_log_loss(y_true, y_pred)\n",
    "    except Exception:\n",
    "        return torch.tensor(0.0, dtype=torch.float32, device=output.device, requires_grad=True)\n",
    "    return torch.tensor(loss_value, dtype=torch.float32, device=output.device, requires_grad=True)\n",
    "\n",
    "\n",
    "class BalancedLogLossMetric:\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error / weight\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        y_true = np.array(target).astype(int)\n",
    "        y_pred = np.array(approxes[0])\n",
    "        nc = np.bincount(y_true)\n",
    "        balanced_logloss = metrics.log_loss(y_true, y_pred, sample_weight=1 / nc[y_true], eps=1e-15)\n",
    "        return balanced_logloss, 1.0\n",
    "\n",
    "\n",
    "class BalancedLogLoss:\n",
    "    y_int = True\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        store_attr()\n",
    "\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        return balanced_log_loss_tensor(inp, targ)\n",
    "\n",
    "    def activation(self, out: Tensor) -> Tensor:\n",
    "        return F.softmax(out, dim=-1)\n",
    "\n",
    "    def decodes(self, out: Tensor) -> Tensor:\n",
    "        return out.argmax(dim=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:19.568684Z",
     "start_time": "2023-08-07T04:04:19.543727Z"
    }
   },
   "id": "b77ae161aa830418"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b952a282729ea46"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import compose, ensemble, impute, pipeline, preprocessing, tree\n",
    "\n",
    "\n",
    "def get_preprocess_pipeline(df, cont_cols, cat_cols, drop_cols):\n",
    "    \"\"\"\n",
    "    Returns a pipeline that performs the following transformations:\n",
    "    * Standard scaling\n",
    "    * Log transformation\n",
    "    * Reciprocal transformation\n",
    "    * Box-Cox transformation\n",
    "    * Yeo-Johnson transformation\n",
    "    * Categorical imputing\n",
    "    * Semi-constant feature binarization\n",
    "\n",
    "    Based on the EDA from https://www.kaggle.com/code/mateuszk013/icr-eda-balanced-learning-with-lgbm-xgb/notebook\n",
    "\n",
    "    :param df: The dataframe to be transformed.\n",
    "    :type df: pandas.DataFrame\n",
    "    :param cont_names: The names of the continuous variables.\n",
    "    :type cont_names: list of str\n",
    "    :param dep_vars: The names of the dependent variables.\n",
    "    :type dep_vars: list of str\n",
    "    \"\"\"\n",
    "\n",
    "    # Identify columns that doesn't follow a normal distribution\n",
    "    # find an appropriate transformation for them to follow a normal distribution\n",
    "    r2_scores = defaultdict(tuple)\n",
    "\n",
    "    for feature in cont_cols:\n",
    "        orig = df[feature].dropna()\n",
    "        _, (*_, R_orig) = stats.probplot(orig, rvalue=True)\n",
    "        _, (*_, R_log) = stats.probplot(np.log(orig), rvalue=True)\n",
    "        _, (*_, R_sqrt) = stats.probplot(np.sqrt(orig), rvalue=True)\n",
    "        _, (*_, R_reci) = stats.probplot(np.reciprocal(orig), rvalue=True)\n",
    "        _, (*_, R_boxcox) = stats.probplot(stats.boxcox(orig)[0], rvalue=True)\n",
    "        _, (*_, R_yeojohn) = stats.probplot(stats.yeojohnson(orig)[0], rvalue=True)\n",
    "        r2_scores[feature] = (\n",
    "            R_orig * R_orig,\n",
    "            R_log * R_log,\n",
    "            R_sqrt * R_sqrt,\n",
    "            R_reci * R_reci,\n",
    "            R_boxcox * R_boxcox,\n",
    "            R_yeojohn * R_yeojohn,\n",
    "        )\n",
    "\n",
    "    r2_scores = pd.DataFrame(\n",
    "        r2_scores,\n",
    "        index=(\"Original\", \"Log\", \"Sqrt\", \"Reciprocal\", \"BoxCox\", \"YeoJohnson\"),\n",
    "    ).T\n",
    "\n",
    "    r2_scores[\"Winner\"] = r2_scores.idxmax(axis=1)\n",
    "\n",
    "    # Identify columns to be transformed\n",
    "    no_transform_cols = r2_scores.query(\"Winner == 'Original'\").index\n",
    "    log_transform_cols = r2_scores.query(\"Winner == 'Log'\").index\n",
    "    reciprocal_transform_cols = r2_scores.query(\"Winner == 'Reciprocal'\").index\n",
    "    boxcox_transform_cols = r2_scores.query(\"Winner == 'BoxCox'\").index\n",
    "    yeojohnson_transform_cols = r2_scores.query(\"Winner == 'YeoJohnson'\").index\n",
    "\n",
    "    # Identify columns that are constant or semi-constant\n",
    "    numeric_descr = df.drop(columns=drop_cols).describe().T\n",
    "    semi_constant_mask = np.isclose(numeric_descr[\"min\"], numeric_descr[\"50%\"])\n",
    "    semi_constant_descr = numeric_descr[semi_constant_mask]\n",
    "    semi_const_cols_thresholds = semi_constant_descr[\"50%\"].to_dict()\n",
    "\n",
    "    # List of columns to be transformed\n",
    "    semi_const_cols = semi_const_cols_thresholds.keys()\n",
    "    no_transform_cols = no_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    log_transform_cols = log_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    reciprocal_transform_cols = reciprocal_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    boxcox_transform_cols = boxcox_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "    yeojohnson_transform_cols = yeojohnson_transform_cols.drop(semi_const_cols, errors=\"ignore\").to_list()\n",
    "\n",
    "    # Transformations\n",
    "    standard_scaling = (\n",
    "        preprocessing.StandardScaler(),\n",
    "        no_transform_cols,\n",
    "    )\n",
    "    log_transform = (\n",
    "        pipeline.make_pipeline(\n",
    "            preprocessing.FunctionTransformer(func=np.log, feature_names_out=\"one-to-one\"),\n",
    "            preprocessing.StandardScaler(),\n",
    "        ),\n",
    "        log_transform_cols,\n",
    "    )\n",
    "    reciprocal_transform = (\n",
    "        pipeline.make_pipeline(\n",
    "            preprocessing.FunctionTransformer(func=np.reciprocal, feature_names_out=\"one-to-one\"),\n",
    "            preprocessing.StandardScaler(),\n",
    "        ),\n",
    "        reciprocal_transform_cols,\n",
    "    )\n",
    "    boxcox_transform = (\n",
    "        preprocessing.PowerTransformer(method=\"box-cox\", standardize=True),\n",
    "        boxcox_transform_cols,\n",
    "    )\n",
    "    yeojohnson_transform = (\n",
    "        preprocessing.PowerTransformer(method=\"yeo-johnson\", standardize=True),\n",
    "        yeojohnson_transform_cols,\n",
    "    )\n",
    "\n",
    "    # Other transformations\n",
    "    categorical_imputing = (\n",
    "        pipeline.make_pipeline(\n",
    "            impute.SimpleImputer(strategy=\"most_frequent\"),\n",
    "            preprocessing.OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    "        ),\n",
    "        cat_cols,  # type: ignore\n",
    "    )\n",
    "    semi_const_transforms = [\n",
    "        (\n",
    "            pipeline.make_pipeline(\n",
    "                impute.SimpleImputer(strategy=\"median\"),\n",
    "                preprocessing.Binarizer(threshold=thresh),\n",
    "            ),\n",
    "            [col],\n",
    "        )\n",
    "        for col, thresh in semi_const_cols_thresholds.items()\n",
    "    ]\n",
    "\n",
    "    return pipeline.make_pipeline(\n",
    "        compose.make_column_transformer(\n",
    "            standard_scaling,\n",
    "            log_transform,\n",
    "            reciprocal_transform,\n",
    "            boxcox_transform,\n",
    "            yeojohnson_transform,\n",
    "            categorical_imputing,\n",
    "            *semi_const_transforms,\n",
    "            remainder=\"drop\",\n",
    "            verbose_feature_names_out=False,\n",
    "        ),\n",
    "        impute.KNNImputer(n_neighbors=10, weights=\"distance\"),\n",
    "    ).set_output(transform=\"pandas\")\n",
    "\n",
    "\n",
    "def get_tree_preprocess_pipeline():\n",
    "    return pipeline.make_pipeline(\n",
    "        impute.KNNImputer(n_neighbors=10, weights=\"distance\"),\n",
    "    ).set_output(transform=\"pandas\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:19.570342Z",
     "start_time": "2023-08-07T04:04:19.555057Z"
    }
   },
   "id": "31d08d53d8f3bcd9"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('./data')\n",
    "output = Path('./output')\n",
    "output.mkdir(exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(path / \"train.csv\", index_col=\"Id\")\n",
    "dep_vars = [\"Class\"]\n",
    "\n",
    "drop_vars = [\"EJ\"]\n",
    "df.drop(columns=drop_vars, inplace=True)\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(df, test_size=0.4, stratify=df[dep_vars], random_state=33)\n",
    "\n",
    "\n",
    "def get_preprocessed_data(train_df, test_df, dep_vars):\n",
    "    cont_names, cat_names = cont_cat_split(df, dep_var=dep_vars)\n",
    "\n",
    "    preprocessor = get_preprocess_pipeline(df, cont_names, cat_names, dep_vars)\n",
    "\n",
    "    # Preprocess training data\n",
    "    X_pre = preprocessor.fit_transform(train_df.drop(columns=dep_vars))\n",
    "    train_df = pd.merge(X_pre, train_df[dep_vars], left_index=True, right_index=True)\n",
    "    X = train_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y = train_df[dep_vars]\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_pre = preprocessor.transform(test_df.drop(columns=dep_vars))\n",
    "    test_df = pd.merge(X_test_pre, test_df[dep_vars], left_index=True, right_index=True)\n",
    "    X_test = test_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y_test = test_df[dep_vars]\n",
    "\n",
    "    return X, y, X_test, y_test\n",
    "\n",
    "\n",
    "def get_tree_preprocessed_data(train_df, test_df, dep_vars):\n",
    "    preprocessor = get_tree_preprocess_pipeline()\n",
    "\n",
    "    # Preprocess training data\n",
    "    X_pre = preprocessor.fit_transform(train_df.drop(columns=dep_vars))\n",
    "    train_df = pd.merge(X_pre, train_df[dep_vars], left_index=True, right_index=True)\n",
    "    X = train_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y = train_df[dep_vars]\n",
    "\n",
    "    # Preprocess test data\n",
    "    X_test_pre = preprocessor.transform(test_df.drop(columns=dep_vars))\n",
    "    test_df = pd.merge(X_test_pre, test_df[dep_vars], left_index=True, right_index=True)\n",
    "    X_test = test_df.drop(columns=dep_vars, errors=\"ignore\")\n",
    "    y_test = test_df[dep_vars]\n",
    "\n",
    "    # Calculate scale_pos_weight\n",
    "    scale_pos_weight = df['Class'].value_counts()[0] / df['Class'].value_counts()[1]\n",
    "\n",
    "    return X, y, X_test, y_test, scale_pos_weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:19.715386Z",
     "start_time": "2023-08-07T04:04:19.586759Z"
    }
   },
   "id": "865eae9e43791a21"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# Resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "def resample(X, y):\n",
    "    sampler = SMOTE()\n",
    "    X_res, y_res = sampler.fit_resample(X, y)\n",
    "    return X_res, y_res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:19.718269Z",
     "start_time": "2023-08-07T04:04:19.626881Z"
    }
   },
   "id": "2e84cd9ab326f67a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model param getters from Optuna"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cae6eddf512b3e"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:03.412990Z",
     "start_time": "2023-08-07T04:23:03.381409Z"
    }
   },
   "outputs": [],
   "source": [
    "best_trials = {\n",
    "    \"lightgbm_with_resampling\": 248,\n",
    "    \"lightgbm_without_resampling\": 220,\n",
    "    \"svc_without_resampling\": 203,\n",
    "    \"svc_with_resampling\": 161,\n",
    "    \"catboost_with_resampling\": 234,\n",
    "    \"catboost_without_resampling\": 223,\n",
    "    \"fastai_with_resampling\": 123,\n",
    "    \"fastai_without_resampling\": 101,\n",
    "    \"tabpfn_without_resampling\": 30,\n",
    "    \"tabpfn_with_resampling\": 65,\n",
    "    \"xgboost_without_resampling\": 210,\n",
    "    \"xgboost_with_resampling\": 179,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "optuna_storage = \"sqlite:///icr-ensemble-experiments.db\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:04.059779Z",
     "start_time": "2023-08-07T04:23:03.791534Z"
    }
   },
   "id": "e06554d32a11fa3f"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "estimator_params = {}\n",
    "for study_name, trial_id in best_trials.items():\n",
    "    study = optuna.load_study(study_name=study_name, storage=optuna_storage)\n",
    "    best_trial = best_trials[study_name]\n",
    "    estimator_params[study_name] = study.trials[trial_id].params"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:10.413138Z",
     "start_time": "2023-08-07T04:23:04.340902Z"
    }
   },
   "id": "5eed160c1ee1e821"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 0.10494454342481872,\n 'degree': 8,\n 'gamma': 3.4748581836487165,\n 'kernel': 'linear'}"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_params[\"svc_with_resampling\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:10.413956Z",
     "start_time": "2023-08-07T04:23:10.375253Z"
    }
   },
   "id": "8ab3342c8064deb"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "def get_xgboost_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = dict(\n",
    "        booster=\"gbtree\",\n",
    "        tree_method='gpu_hist',\n",
    "        gpu_id=0,\n",
    "        predictor='gpu_predictor',\n",
    "        enable_categorical=True,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "    ) | optuna_params\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        **params,\n",
    "        eval_metric=balanced_log_loss,\n",
    "    )\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    test_loss = balanced_log_loss(y_test.values.ravel(), model.predict_proba(X_test))\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:24.423111Z",
     "start_time": "2023-08-07T04:04:24.392922Z"
    }
   },
   "id": "58b6004001f46e2a"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2717630661008243\n",
      "Test loss: 0.25831930235898776\n",
      "Validation loss: 0.3568297170940195\n",
      "Test loss: 0.31751080701618967\n"
     ]
    }
   ],
   "source": [
    "xgboost_with_resampling = get_xgboost_estimator(\"xgboost_with_resampling\")\n",
    "xgboose_without_resampling = get_xgboost_estimator(\"xgboost_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:04:58.563322Z",
     "start_time": "2023-08-07T04:04:24.403069Z"
    }
   },
   "id": "7c4f8fcb9a435e64"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def get_lightgbm_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = dict(\n",
    "        boosting_type=\"gbdt\",\n",
    "        # device=\"gpu\",\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        data_sample_strategy=\"bagging\",\n",
    "        n_jobs=-1,\n",
    "    ) | optuna_params\n",
    "\n",
    "    model = LGBMClassifier(**params, objective=\"binary\", verbosity=-1)\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit, eval_metric=balanced_log_loss)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    test_loss = balanced_log_loss(y_test.values.ravel(), model.predict_proba(X_test))\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:05:48.337536Z",
     "start_time": "2023-08-07T04:05:48.325108Z"
    }
   },
   "id": "abb393dd37adc5f"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.27788775297800195\n",
      "Test loss: 0.2913405820647997\n",
      "Validation loss: 0.3391997182685824\n",
      "Test loss: 0.34534098102084476\n"
     ]
    }
   ],
   "source": [
    "lightgbm_with_resampling = get_lightgbm_estimator(\"lightgbm_with_resampling\")\n",
    "lightgbm_without_resampling = get_lightgbm_estimator(\"lightgbm_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:06:41.971730Z",
     "start_time": "2023-08-07T04:05:48.861050Z"
    }
   },
   "id": "dbe6618be76154f9"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def get_svc_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test = get_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = dict(\n",
    "        probability=True,\n",
    "    ) | optuna_params\n",
    "\n",
    "    model = svm.SVC(**params)\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    test_loss = balanced_log_loss(y_test.values.ravel(), model.predict_proba(X_test))\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:08:38.701269Z",
     "start_time": "2023-08-07T04:08:38.696483Z"
    }
   },
   "id": "a4fc52092cc67f58"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5354314436217044\n",
      "Test loss: 0.5497892853161306\n",
      "Validation loss: 0.4217511061671817\n",
      "Test loss: 0.3766329745870105\n"
     ]
    }
   ],
   "source": [
    "svc_with_resampling = get_svc_estimator(\"svc_with_resampling\")\n",
    "svc_without_resampling = get_svc_estimator(\"svc_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:08:43.455364Z",
     "start_time": "2023-08-07T04:08:39.448007Z"
    }
   },
   "id": "6e21e919afb9b5a"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def get_catboost_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test, scale_pos_weight = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    params = dict(\n",
    "        grow_policy=\"SymmetricTree\",\n",
    "        verbose=0,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "    ) | optuna_params\n",
    "\n",
    "    model = CatBoostClassifier(**params, eval_metric=BalancedLogLossMetric())\n",
    "\n",
    "    skf = model_selection.RepeatedStratifiedKFold(n_splits=7, n_repeats=3)\n",
    "\n",
    "    val_loss_list = []\n",
    "\n",
    "    for i, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx].values.ravel()\n",
    "\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx].values.ravel()\n",
    "\n",
    "        X_fit, y_fit = X_train, y_train\n",
    "        if should_resample:\n",
    "            X_fit, y_fit = resample(X_train, y_train)\n",
    "\n",
    "        model.fit(X_fit, y_fit)\n",
    "\n",
    "        val_preds = model.predict_proba(X_val)\n",
    "        val_loss = balanced_log_loss(y_val, val_preds)\n",
    "\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "    test_loss = balanced_log_loss(y_test.values.ravel(), model.predict_proba(X_test))\n",
    "    print(f\"Validation loss: {np.mean(val_loss_list)}\")\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:11:25.972656Z",
     "start_time": "2023-08-07T04:11:25.957132Z"
    }
   },
   "id": "9944a596ce12e5ef"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.29200997680502094\n",
      "Test loss: 0.3182577856802042\n",
      "Validation loss: 0.3422437693802506\n",
      "Test loss: 0.3090137379347216\n"
     ]
    }
   ],
   "source": [
    "catboost_with_resampling = get_catboost_estimator(\"catboost_with_resampling\")\n",
    "catboost_without_resampling = get_catboost_estimator(\"catboost_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:12:27.826556Z",
     "start_time": "2023-08-07T04:11:26.427735Z"
    }
   },
   "id": "843542a6590cfbb4"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "\n",
    "def get_tabpfn_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    params = estimator_params[name]\n",
    "    X, y, X_test, y_test, _ = get_tree_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    model = TabPFNClassifier(\n",
    "        device=\"cuda\",\n",
    "        only_inference=False,\n",
    "        **params,\n",
    "    )\n",
    "\n",
    "    X_fit, y_fit = X, y\n",
    "    if should_resample:\n",
    "        X_fit, y_fit = resample(X, y)\n",
    "\n",
    "    model.fit(X_fit, y_fit.values.ravel())\n",
    "\n",
    "    test_loss = balanced_log_loss(y_test.values.ravel(), model.predict_proba(X_test))\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:15:50.546903Z",
     "start_time": "2023-08-07T04:15:50.522756Z"
    }
   },
   "id": "9d8f8c276920b3a2"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Test loss: 0.4888267602549823\n",
      "!! Warning: GPyTorch must be installed !!\n",
      "Using style prior: True\n",
      "Using cuda device\n",
      "Using a Transformer with 25.82 M parameters\n",
      "Test loss: 0.4586789624230296\n"
     ]
    }
   ],
   "source": [
    "tabpfn_with_resampling = get_tabpfn_estimator(\"tabpfn_with_resampling\")\n",
    "tabpfn_without_resampling = get_tabpfn_estimator(\"tabpfn_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:15:53.969662Z",
     "start_time": "2023-08-07T04:15:51.169049Z"
    }
   },
   "id": "7ab7a4c100ba5481"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "from fastai.tabular.all import (tabular_learner, tabular_config, TabularDataLoaders, CategoryBlock, FocalLossFlat,\n",
    "                                TrainTestSplitter, EarlyStoppingCallback)\n",
    "\n",
    "\n",
    "def get_fastai_estimator(name: str):\n",
    "    should_resample = name.endswith(\"with_resampling\")\n",
    "\n",
    "    optuna_params = estimator_params[name]\n",
    "    X, y, X_test, y_test = get_preprocessed_data(train_df, test_df, dep_vars)\n",
    "\n",
    "    training_data = pd.merge(X, y, left_index=True, right_index=True)\n",
    "\n",
    "    if should_resample:\n",
    "        X_res, y_res = resample(X, y)\n",
    "        training_data = pd.merge(X_res, y_res, left_index=True, right_index=True)\n",
    "\n",
    "    testing_data = pd.merge(X_test, y_test, left_index=True, right_index=True)\n",
    "\n",
    "    layers_map = {\n",
    "        0: [2048, 1024, 512],\n",
    "        1: [2048, 1024, 512, 256],\n",
    "        2: [2048, 1024, 512, 256, 128],\n",
    "        3: [2048, 1024, 512, 256, 128],\n",
    "        4: [2048, 1024, 512, 256, 128, 64],\n",
    "        5: [2048, 1024, 512, 256, 128, 64, 32],\n",
    "        6: [2048, 1024, 512, 256, 128, 64, 32, 16],\n",
    "        7: [512, 256, 128, 64, 32, 16],\n",
    "        8: [256, 128, 64, 32, 16],\n",
    "        9: [128, 64, 32, 16],\n",
    "        10: [64, 32, 32, 16, 8],\n",
    "    }\n",
    "\n",
    "    bs = optuna_params.get(\"bs\")\n",
    "    epochs = optuna_params.get(\"epochs\")\n",
    "    layers_choice = optuna_params.get(\"layers_choice\")\n",
    "    layers = layers_map[layers_choice]\n",
    "\n",
    "    config = tabular_config(\n",
    "        ps=optuna_params.get(\"ps\"),\n",
    "        use_bn=optuna_params.get(\"use_bn\"),\n",
    "        bn_final=optuna_params.get(\"bn_final\"),\n",
    "        bn_cont=optuna_params.get(\"bn_cont\"),\n",
    "        lin_first=optuna_params.get(\"lin_first\"),\n",
    "    )\n",
    "\n",
    "    dls = TabularDataLoaders.from_df(\n",
    "        training_data,\n",
    "        y_names=dep_vars,\n",
    "        y_block=CategoryBlock,\n",
    "        bs=bs,\n",
    "        splits=TrainTestSplitter(\n",
    "            test_size=0.2,\n",
    "            stratify=train_df[dep_vars],\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    model = tabular_learner(\n",
    "        dls,\n",
    "        loss_func=FocalLossFlat(gamma=optuna_params.get(\"gamma\")),\n",
    "        layers=layers,\n",
    "        config=config,\n",
    "        cbs=[\n",
    "            EarlyStoppingCallback(min_delta=0.1, patience=5),\n",
    "        ],\n",
    "        wd=optuna_params.get(\"wd\"),\n",
    "        wd_bn_bias=optuna_params.get(\"wd_bn_bias\"),\n",
    "    )\n",
    "\n",
    "    with model.no_logging(), model.no_bar():\n",
    "        model.fit_one_cycle(epochs)\n",
    "\n",
    "    ypreds, targs = model.get_preds()\n",
    "    val_loss = balanced_log_loss_tensor(ypreds, targs).item()\n",
    "\n",
    "    test_dl = dls.test_dl(testing_data)\n",
    "    ypreds, targs = model.get_preds(dl=test_dl)\n",
    "    test_loss = balanced_log_loss_tensor(ypreds, targs).item()\n",
    "\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    print(f\"Test loss: {test_loss}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:53.856640Z",
     "start_time": "2023-08-07T04:23:53.845558Z"
    }
   },
   "id": "a3fad9c4bca54f29"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 2: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.23553065955638885\n",
      "Test loss: 0.2887076139450073\n",
      "No improvement since epoch 6: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n<style>\n    /* Turns off some styling */\n    progress {\n        /* gets rid of default border in Firefox and Opera. */\n        border: none;\n        /* Needs to be in here for Safari polyfill so background images work as expected. */\n        background-size: auto;\n    }\n    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n    }\n    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n        background: #F44336;\n    }\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      <progress value='0' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3589724898338318\n",
      "Test loss: 0.34441179037094116\n"
     ]
    }
   ],
   "source": [
    "fastai_with_resampling = get_fastai_estimator(\"fastai_with_resampling\")\n",
    "fastai_without_resampling = get_fastai_estimator(\"fastai_without_resampling\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-07T04:23:58.376007Z",
     "start_time": "2023-08-07T04:23:54.216761Z"
    }
   },
   "id": "43f37562a0493f74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30fc5978c10dd9bd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
